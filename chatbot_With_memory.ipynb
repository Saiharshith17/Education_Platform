{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e1e4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import uuid\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "import redis\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2762840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd955e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDIS_URL=os.getenv(\"REDIS_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbea4dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redis://Harshith:1AP33718.s@redis-10786.crce206.ap-south-1-1.ec2.redns.redis-cloud.com:10786\n"
     ]
    }
   ],
   "source": [
    "print(REDIS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a0290c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    model = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cb2f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aede30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdb = redis.Redis.from_url(REDIS_URL, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bac236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str):\n",
    "    return RedisChatMessageHistory(\n",
    "        session_id=session_id,\n",
    "        url=REDIS_URL,  \n",
    "        ttl=3600  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c608ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHAIN(llm):\n",
    "    system_prompt=\"\"\"You are Educational Chatbot, a highly knowledgeable and professional AI assistant for solving engineering students questions.\n",
    "\n",
    "Your responsibilities are as follows:\n",
    "1. You must **only** answer questions related to **engineering**.Mainly try to focus on \n",
    " - Artificial Intelligence\n",
    " - Frontened development\n",
    " - Backened development\n",
    " - Machine Learning\n",
    " - Generative AI\n",
    " - DSA\n",
    " - Fundamentals of Computers\n",
    " - Fullstack Development\n",
    "\n",
    "2. If a user asks any question **outside the above domain**, **politely reject** the request by saying:\n",
    "> \"I'm here to assist with engineering-related topics only. Please ask a question within the engineering domain.\"\n",
    "\n",
    "3. Always give **precise**, **professionally written**, and **well-structured answers** with minimal but relevant explanations.\n",
    "\n",
    "4. Avoid any kind of informal tone, unnecessary elaboration, or irrelevant context.\n",
    "\n",
    "5. When applicable, use technical language suitable for students and aspiring engineers, and explain terms clearly without oversimplifying.\n",
    "\n",
    "Your goal is to serve as a reliable academic support system for engineering students.\n",
    "\"\"\"\n",
    "    prompt=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "        (\"system\",system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "        ]\n",
    "    )\n",
    "    chain=prompt | llm\n",
    "    return RunnableWithMessageHistory(\n",
    "        runnable=chain,\n",
    "        get_session_history=get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4902fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def model_with_memory(message,user_id,llm, rdb):\n",
    "    chain=CHAIN(llm)\n",
    "    session_key = f\"user_session:{user_id}\"\n",
    "    session_id = rdb.get(session_key)\n",
    "    if not session_id:\n",
    "        session_id = str(uuid4())\n",
    "        rdb.set(session_key, session_id, ex=3600)\n",
    "\n",
    "    result = await chain.ainvoke(\n",
    "        {\"input\": message},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    history = get_session_history(session_id).messages\n",
    "    full_chat = []\n",
    "    for msg in history:\n",
    "        role = \"User\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        full_chat.append(f\"{role}: {msg.content}\")\n",
    "    \n",
    "    return result.content,full_chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f7791f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LangChain:**\n",
      "LangChain is an open-source framework for building applications that utilize large language models (LLMs) and other AI technologies. It provides a set of tools and APIs for developers to create custom AI-powered applications, such as chatbots, virtual assistants, and content generation tools.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Modular Architecture**: LangChain has a modular architecture that allows developers to easily integrate different LLMs and AI models into their applications.\n",
      "2. **API-First Approach**: LangChain provides a robust API that enables developers to access and utilize the framework's functionality programmatically.\n",
      "3. **Support for Multiple LLMs**: LangChain supports a wide range of LLMs, including popular models like LLaMA, PaLM, and BERT.\n",
      "4. **Customizable**: LangChain allows developers to customize the behavior and functionality of their AI-powered applications using a variety of configuration options and plugins.\n",
      "5. **Scalable**: LangChain is designed to scale horizontally, making it suitable for large-scale deployments and high-traffic applications.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "1. **Chatbots and Virtual Assistants**: LangChain can be used to build custom chatbots and virtual assistants that utilize LLMs to understand and respond to user input.\n",
      "2. **Content Generation**: LangChain can be used to generate high-quality content, such as articles, stories, and product descriptions, using LLMs.\n",
      "3. **Language Translation**: LangChain can be used to build language translation applications that utilize LLMs to translate text and speech in real-time.\n",
      "4. **Sentiment Analysis**: LangChain can be used to build sentiment analysis applications that utilize LLMs to analyze and understand user sentiment and emotions.\n",
      "5. **Text Summarization**: LangChain can be used to build text summarization applications that utilize LLMs to summarize long pieces of text into concise and meaningful summaries.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Faster Development**: LangChain provides a set of pre-built tools and APIs that enable developers to build AI-powered applications faster and more efficiently.\n",
      "2. **Improved Accuracy**: LangChain utilizes LLMs to provide highly accurate and relevant results, improving the overall quality of AI-powered applications.\n",
      "3. **Increased Customization**: LangChain allows developers to customize the behavior and functionality of their AI-powered applications, enabling them to meet specific use cases and requirements.\n",
      "4. **Scalability**: LangChain is designed to scale horizontally, making it suitable for large-scale deployments and high-traffic applications.\n",
      "\n",
      "**Technical Requirements:**\n",
      "\n",
      "1. **Python 3.8+**: LangChain is built using Python 3.8+ and requires a compatible Python environment to run.\n",
      "2. **TensorFlow or PyTorch**: LangChain supports both TensorFlow and PyTorch, and requires one of these frameworks to be installed.\n",
      "3. **GPU Support**: LangChain can utilize GPU acceleration to improve performance, but it is not required.\n",
      "['User: what are distributed systems', 'AI: **Distributed Systems:**\\nA distributed system is a collection of independent computers or nodes that communicate with each other to achieve a common goal or provide a service. These nodes can be geographically dispersed and are connected through a network, such as the internet.\\n\\n**Key Characteristics:**\\n\\n1. **Decentralization**: No single node controls the entire system.\\n2. **Autonomy**: Each node operates independently, making its own decisions.\\n3. **Distribution**: Nodes are dispersed across multiple locations.\\n4. **Concurrency**: Multiple nodes can perform tasks simultaneously.\\n5. **Fault Tolerance**: The system can continue to function even if one or more nodes fail.\\n\\n**Types of Distributed Systems:**\\n\\n1. **Client-Server Architecture**: A centralized server provides services to multiple clients.\\n2. **Peer-to-Peer (P2P) Architecture**: Nodes act as both clients and servers, sharing resources directly.\\n3. **Cluster Computing**: A group of nodes work together to achieve a common goal, often used in high-performance computing.\\n\\n**Benefits:**\\n\\n1. **Scalability**: Distributed systems can handle increased load by adding more nodes.\\n2. **Reliability**: Fault tolerance ensures the system remains operational even if some nodes fail.\\n3. **Improved Performance**: Tasks can be parallelized, reducing overall processing time.\\n\\n**Challenges:**\\n\\n1. **Communication Overhead**: Nodes must communicate with each other, introducing latency and overhead.\\n2. **Synchronization**: Ensuring data consistency and coordination among nodes can be complex.\\n3. **Security**: Distributed systems are more vulnerable to attacks and data breaches.\\n\\n**Real-World Applications:**\\n\\n1. **Cloud Computing**: Distributed systems provide the foundation for cloud infrastructure.\\n2. **Social Media**: Distributed systems enable social media platforms to handle large user bases.\\n3. **Blockchain**: A decentralized, distributed ledger technology used in cryptocurrency and other applications.\\n\\nIn summary, distributed systems are designed to provide scalability, reliability, and improved performance by leveraging multiple nodes working together. However, they also introduce new challenges, such as communication overhead, synchronization, and security concerns.', 'User: what are uses of it', 'AI: **Uses of Distributed Systems:**\\n\\n1. **Cloud Computing**: Distributed systems provide the foundation for cloud infrastructure, enabling scalable and on-demand access to computing resources.\\n2. **Big Data Processing**: Distributed systems are used to process large datasets in parallel, making them ideal for big data analytics and machine learning applications.\\n3. **Social Media**: Distributed systems enable social media platforms to handle large user bases, providing scalable and reliable access to user data and services.\\n4. **Blockchain**: Distributed systems are used to implement blockchain technology, enabling secure and decentralized transactions.\\n5. **Internet of Things (IoT)**: Distributed systems are used to manage and process data from IoT devices, enabling real-time monitoring and control.\\n6. **Gaming**: Distributed systems are used to create online gaming platforms, providing scalable and low-latency access to game servers.\\n7. **Financial Transactions**: Distributed systems are used to process financial transactions, providing secure and reliable access to financial data and services.\\n8. **Scientific Research**: Distributed systems are used to simulate complex scientific models, such as climate modeling and molecular dynamics.\\n9. **Cybersecurity**: Distributed systems are used to detect and respond to cyber threats, providing real-time monitoring and incident response.\\n10. **Artificial Intelligence**: Distributed systems are used to train and deploy AI models, enabling scalable and efficient processing of large datasets.\\n\\n**Industry-Specific Applications:**\\n\\n1. **Healthcare**: Distributed systems are used to manage electronic health records, provide telemedicine services, and analyze medical imaging data.\\n2. **Finance**: Distributed systems are used to process financial transactions, manage risk, and provide investment analysis.\\n3. **Retail**: Distributed systems are used to manage supply chains, provide personalized customer experiences, and analyze sales data.\\n4. **Manufacturing**: Distributed systems are used to manage production lines, monitor equipment, and optimize supply chains.\\n5. **Energy**: Distributed systems are used to manage smart grids, monitor energy usage, and optimize energy distribution.\\n\\n**Emerging Trends:**\\n\\n1. **Edge Computing**: Distributed systems are being used to enable edge computing, where data is processed at the edge of the network, reducing latency and improving real-time processing.\\n2. **Serverless Computing**: Distributed systems are being used to enable serverless computing, where applications are deployed without the need for server management.\\n3. **Fog Computing**: Distributed systems are being used to enable fog computing, where data is processed at the edge of the network, but also stored and processed in the cloud.', 'User: what langchain', \"AI: **LangChain:**\\nLangChain is an open-source framework for building applications that utilize large language models (LLMs) and other AI technologies. It provides a set of tools and APIs for developers to create custom AI-powered applications, such as chatbots, virtual assistants, and content generation tools.\\n\\n**Key Features:**\\n\\n1. **Modular Architecture**: LangChain has a modular architecture that allows developers to easily integrate different LLMs and AI models into their applications.\\n2. **API-First Approach**: LangChain provides a robust API that enables developers to access and utilize the framework's functionality programmatically.\\n3. **Support for Multiple LLMs**: LangChain supports a wide range of LLMs, including popular models like LLaMA, PaLM, and BERT.\\n4. **Customizable**: LangChain allows developers to customize the behavior and functionality of their AI-powered applications using a variety of configuration options and plugins.\\n5. **Scalable**: LangChain is designed to scale horizontally, making it suitable for large-scale deployments and high-traffic applications.\\n\\n**Use Cases:**\\n\\n1. **Chatbots and Virtual Assistants**: LangChain can be used to build custom chatbots and virtual assistants that utilize LLMs to understand and respond to user input.\\n2. **Content Generation**: LangChain can be used to generate high-quality content, such as articles, stories, and product descriptions, using LLMs.\\n3. **Language Translation**: LangChain can be used to build language translation applications that utilize LLMs to translate text and speech in real-time.\\n4. **Sentiment Analysis**: LangChain can be used to build sentiment analysis applications that utilize LLMs to analyze and understand user sentiment and emotions.\\n5. **Text Summarization**: LangChain can be used to build text summarization applications that utilize LLMs to summarize long pieces of text into concise and meaningful summaries.\\n\\n**Benefits:**\\n\\n1. **Faster Development**: LangChain provides a set of pre-built tools and APIs that enable developers to build AI-powered applications faster and more efficiently.\\n2. **Improved Accuracy**: LangChain utilizes LLMs to provide highly accurate and relevant results, improving the overall quality of AI-powered applications.\\n3. **Increased Customization**: LangChain allows developers to customize the behavior and functionality of their AI-powered applications, enabling them to meet specific use cases and requirements.\\n4. **Scalability**: LangChain is designed to scale horizontally, making it suitable for large-scale deployments and high-traffic applications.\\n\\n**Technical Requirements:**\\n\\n1. **Python 3.8+**: LangChain is built using Python 3.8+ and requires a compatible Python environment to run.\\n2. **TensorFlow or PyTorch**: LangChain supports both TensorFlow and PyTorch, and requires one of these frameworks to be installed.\\n3. **GPU Support**: LangChain can utilize GPU acceleration to improve performance, but it is not required.\"]\n"
     ]
    }
   ],
   "source": [
    "response,_=await model_with_memory(\"what langchain\",100,llm,rdb)\n",
    "print(response)\n",
    "print(_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "education",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
